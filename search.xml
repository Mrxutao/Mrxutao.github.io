<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>�������</title>
      <link href="/2019/12/23/%E6%B5%8B%E8%AF%95/"/>
      <url>/2019/12/23/%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p>�������С��ʱ��:<br>        ��Ȼʱ���ǲ�����ģ��������޷���׷�ء�</p><p>����Լ��Ҵ���ӹµ���ϰ��꣬��ȥ���걧�����ѣ��ҽ��ץס�°���������һ��ʱ�⣬ȥ�¸ҵ�����ʲô�ɡ���Щ��ƽ�տ����ֺ��µģ����������ܾõ����룬�ֲ���������յ����ꡣ</p><p>������Ψһ��ƽ�Ķ������¾������������ֿ��˵�ʱ���ˡ���ʱ����ǰ��û�еȼ���û��ƶ����û�����衣</p><p>��ȥĪ��׷���������ɼ���</p><p>׷��ʱ�䳤�ӵ�Ψһ��ʽ�����ǽ��ץס���ڣ����ڵ�����ÿһ��ÿһ�롣</p><p>����Ŀ�ĲԲ԰׷����������ƣ�ֻ��ʱ��ĵ�Ӱ��</p><p>��ص�����ʫ��͸��ݽ�겣�����ʱ�����ױ������ԶԶ��ȥ����˫����ת�ĳ�������ǣ�����������ӵ�����ˮ������⣬����ʱ������������ŵķ��٣�������ȹ�Ƿ����</p><p>ʱ��������ָ��䣬Ҳ��������������</p><p>�Ұ��㣬ʱ�䡣</p><p>����пᣬȴ���ᣬ���ⲨӰ�����ǳǳ����ۺ�ǳǳ��Ц�⡣�����ɬ��ȴ�����õεδ������ң�������һ�����緫��������</p><p>����������ì�ܵĿ�������̹ǵ��ϡ��㿶�������ģ����۴��ģ���Ӳ�����һƬ�Ʋʣ�ȴ�����ư����ÿһƬ�������������˵Ļ���Ц�����Ҳ�����ǻں޵���������������ʷ���������δ����</p><p>������������˵�Ů�ӣ���δ̤���뷿һ������ҷ����磬����������������</p><p>�ޣ�ʱ�䣬����Щ������Щ��</p><p>�Ҳ�Ը�������������ҵĸ�ĸ������ȥ�����������͵ı�Ӱ��¶��ʱ�����ֻԸһֱ����������Ǹ�СŮ��������Ц�ţ�������һ���������������</p><p>�ޣ�������Щ������Щ��</p><p>�����˺����ǵĳɳ��������ǵ����������ǵ���ͣ�㣬��������ɽüͷ���ǧ��һ����������������±��������ݳ�����Ӱ�ӡ������ҳ�˯��������룬�����������ô��˯������ʱ������ϸ���Ҫ���������</p><p>����Щ������Щ��</p><p>��ʱ�ⲻҪ��ȥ�����ǲ��̿�����İ�ͷ��</p><p>��һ������Ϊ��һ����Ȼ�����ɣ�</p><p>��һ�е��⽣Ӱһ���Ƶ�����Ļ��᣻</p><p>��һ�б������һ����Ǹ�����ɣ�</p><p>��һ�к���ɽ��һ����ͷ��ʼ�Ļ��ᡣ</p><p>������һ�����ᣬ��ʱ�������һ�����������㡣</p><p>������һ�����ᣬ������ʱ����ð�������������촽���¶ȡ�</p><p>end</p>]]></content>
      
      
      
        <tags>
            
            <tag> ���� </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>wz</title>
      <link href="/2018/12/24/XT/"/>
      <url>/2018/12/24/XT/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>java中关于null对象容错处理</title>
      <link href="/2018/12/24/java%E4%B8%AD%E5%85%B3%E4%BA%8Enull%E5%AF%B9%E8%B1%A1%E5%AE%B9%E9%94%99%E5%A4%84%E7%90%86/"/>
      <url>/2018/12/24/java%E4%B8%AD%E5%85%B3%E4%BA%8Enull%E5%AF%B9%E8%B1%A1%E5%AE%B9%E9%94%99%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>在 Thinking in Java 看到这样一段话：</p><p>Primitives that are fields in a class are automatically initialized to zero, as noted in the Everything Is an Object chapter. But the object references are initialized to null, and if you try to call methods for any of them, you’ll get an exception-a runtime error. Conveniently, you can still print a null reference without throwing an exception.</p><p>大意是：原生类型会被自动初始化为 0，但是对象引用会被初始化为 null，如果你尝试调用该对象的方法，就会抛出空指针异常。通常，你可以打印一个 null 对象而不会抛出异常。</p><p>第一句相信大家都会容易理解，这是类型初始化的基础知识，但是第二句就让我很疑惑：为什么打印一个 null 对象不会抛出异常？带着这个疑问，我开始了解惑之旅。下面我将详细阐述我解决这个问题的思路，并且深入 JDK 源码找到问题的答案。</p><p>解决问题的过程</p><p>可以发现，其实这个问题有几种情况，所以我们分类讨论各种情况，看最后能不能得到答案。</p><p>首先，我们把这个问题分解为三个小问题，逐一解决。</p><p>第一个问题</p><p>直接打印 null 的 String 对象，会得到什么结果？</p><p>String s = null;<br>System.out.print(s);</p><p>运行的结果是</p><p>null</p><p>果然如书上说的没有抛出异常，而是打印了null。显然问题的线索在于print函数的源码中。我们找到print的源码：</p><p>public void print(String s) {<br>    if (s == null) {<br>        s = “null”;<br>    }<br>    write(s);<br>}</p><p>看到源码才发现原来就只是加了一句判断而已，简单粗暴，可能你对 JDK 的简单实现有点失望了。放心，第一个问题只是开胃菜而已，大餐还在后面。</p><p>第二个问题</p><p>打印一个 null 的非 String 对象，例如说 Integer：</p><p>Integer i = null;<br>System.out.print(i);</p><p>运行的结果不出意料：</p><p>null</p><p>我们再去看看print的源码：</p><p>public void print(Object obj) {<br>    write(String.valueOf(obj));<br>}</p><p>有点不一样的了，看来秘密藏在valueOf里面。</p><p>public static String valueOf(Object obj) {<br>    return (obj == null) ? “null” : obj.toString();<br>}</p><p>看到这里，我们终于发现了打印 null 对象不会抛出异常的秘密。print方法对 String 对象和非 String 对象分开进行处理。</p><p>String 对象：直接判断是否为 null，如果为 null 给 null 对象赋值为”null”。</p><p>非 String 对象：通过调用String.valueOf方法，如果是 null 对象，就返回”null”，否则调用对象的toString方法。</p><p>通过上面的处理，可以保证打印 null 对象不会出错。</p><p>到这里，本文就应该结束了。<br>什么？说好的大餐呢？上面还不够塞牙缝呢。<br>开玩笑啦。下面我们来探讨第三个问题。</p><p>第三个问题（隐藏的大餐）</p><p>null 对象与字符串拼接会得到什么结果？</p><p>String s = null;<br>s = s + “!”;<br>System.out.print(s);’</p><p>结果可能你也猜到了：</p><p>null!</p><p>为什么呢？跟踪代码运行可以发现，这回跟print没有什么关系。但是上面的代码就调用了print函数，不是它会是谁呢？+的嫌疑最大，但是+又不是函数，我们怎么看到它的源代码？这种情况，唯一的解释就是编译器动了手脚，天网恢恢，疏而不漏，找不到源代码，我们可以去看看编译器生成的字节码。</p><p>L0<br> LINENUMBER 27 L0<br> ACONST_NULL<br> ASTORE 1<br>L1<br> LINENUMBER 28 L1<br> NEW java/lang/StringBuilder<br> DUP<br> INVOKESPECIAL java/lang/StringBuilder.<init> ()V<br> ALOAD 1<br> INVOKEVIRTUAL java/lang/StringBuilder.append (Ljava/lang/String;)Ljava/lang/StringBuilder;<br> LDC “!”<br> INVOKEVIRTUAL java/lang/StringBuilder.append (Ljava/lang/String;)Ljava/lang/StringBuilder;<br> INVOKEVIRTUAL java/lang/StringBuilder.toString ()Ljava/lang/String;<br> ASTORE 1<br>L2<br> LINENUMBER 29 L2<br> GETSTATIC java/lang/System.out : Ljava/io/PrintStream;<br> ALOAD 1<br> INVOKEVIRTUAL java/io/PrintStream.print (Ljava/lang/String;)V</init></p><p>看了上面的字节码是不是一头雾水？这里我们就要扯开话题，来侃侃+字符串拼接的原理了。</p><p>编译器对字符串相加会进行优化，首先实例化一个StringBuilder，然后把相加的字符串按顺序append，最后调用toString返回一个String对象。不信你们看看上面的字节码是不是出现了StringBuilder。详细的解释参考这篇文章 Java细节：字符串的拼接。</p><p>String s = “a” + “b”;<br>//等价于<br>StringBuilder sb = new StringBuilder();<br>sb.append(“a”);<br>sb.append(“b”);<br>String s = sb.toString();</p><p>再回到我们的问题，现在我们知道秘密在StringBuilder.append函数的源码中。</p><p>//针对 String 对象<br>public AbstractStringBuilder append(String str) {<br>    if (str == null)<br>        return appendNull();<br>    int len = str.length();<br>    ensureCapacityInternal(count + len);<br>    str.getChars(0, len, value, count);<br>    count += len;<br>    return this;<br>}<br>//针对非 String 对象<br>public AbstractStringBuilder append(Object obj) {<br>    return append(String.valueOf(obj));<br>}</p><p>private AbstractStringBuilder appendNull() {<br>    int c = count;<br>    ensureCapacityInternal(c + 4);<br>    final char[] value = this.value;<br>    value[c++] = ‘n’;<br>    value[c++] = ‘u’;<br>    value[c++] = ‘l’;<br>    value[c++] = ‘l’;<br>    count = c;<br>    return this;<br>}</p><p>现在我们恍然大悟，append函数如果判断对象为 null，就会调用appendNull，填充”null”。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>你的名称</title>
      <link href="/2018/12/23/%E4%BD%A0%E7%9A%84%E5%90%8D%E7%A7%B0/"/>
      <url>/2018/12/23/%E4%BD%A0%E7%9A%84%E5%90%8D%E7%A7%B0/</url>
      
        <content type="html"><![CDATA[<p>在秋日里，小遇时光:<br>        既然时间是不可逆的，它总是无法被追回。</p><p>面对自己匆匆又庸碌的上半年，除去唏嘘抱憾不已，且紧紧抓住下半年这最后的一点时光，去勇敢的做点什么吧。那些你平日渴望又害怕的，叫醒你打盹很久的梦想，弥补这颗粒无收的逝年。</p><p>人世间唯一公平的东西，怕就是这捧任性又可人的时间了。在时间面前，没有等级，没有贫贱，没有欺凌。</p><p>逝去莫可追，将来不可见。</p><p>追逐时间长河的唯一方式，就是紧紧抓住现在，现在的她，每一分每一秒。</p><p>那满目的苍苍白发和深深皱纹，只是时间的倒影。</p><p>深藏的满腹诗书和高屋建瓴，才是时间的梳妆。倘若远远望去，这双眼流转的沉甸甸的睿智，这柔软心灵涤荡的如水般的善意，恍若时间撩起的最优雅的发髻，欢愉在裙角飞扬里。</p><p>时光流走在指缝间，也静卧在柔软的心里。</p><p>我爱你，时间。</p><p>你虽残酷，却温柔，流光波影里，是你浅浅的泪痕和浅浅的笑意。你虽苦涩，却甘甜，用滴滴答答的琴弦，奏响了一首首如帆的生命。</p><p>你是人们最矛盾的渴望，最刻骨的虔诚。你慷慨又吝啬，无论春夏，你从不带走一片云彩，却风卷残云般剥掉每一片光阴。你在世人的欢歌笑语里，你也在他们悔恨的眼泪里。你雕塑着历史，你挥逑着未来。</p><p>你是世间最可人的女子，尚未踏出闺房一步，便芬芳四溢，带走了整个冬季。</p><p>噢，时间，且慢些，且慢些。</p><p>我不愿看到你拉扯着我的父母慢慢老去，将他们佝偻的背影暴露在时光里。我只愿一直做你梦里的那个小女孩，淡淡笑着，流连在一个叫做梦想的隧道里。</p><p>噢，你且慢些，且慢些。</p><p>别打搅了孩子们的成长，少年们的桀骜，青年们的马不停蹄，中年们如山眉头里的千钧一发，老人们在阳光下被拉得瘦瘦长长的影子。还有我沉睡多年的梦想，静谧无声的敲打出睡莲绽放时的轻声细语，不要打搅了它。</p><p>且慢些，且慢些。</p><p>让时光不要老去，我们不忍看见你的白头。</p><p>给一切无能为力一个释然的理由；</p><p>给一切刀光剑影一个云淡风轻的机会；</p><p>给一切悲欢离合一个道歉的理由；</p><p>给一切海誓山盟一个从头开始的机会。</p><p>给你我一个机会，在时光里，画出一笔最美的永恒。</p><p>给你我一个机会，在曼妙时光里，用爱的絮语，量出你嘴唇的温度。</p><p>end</p>]]></content>
      
      
      
        <tags>
            
            <tag> 你的名称 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于MQ的一些总结和区别</title>
      <link href="/2018/12/12/%E5%85%B3%E4%BA%8EMQ%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93%E5%92%8C%E5%8C%BA%E5%88%AB/"/>
      <url>/2018/12/12/%E5%85%B3%E4%BA%8EMQ%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93%E5%92%8C%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>博主有两位朋友分别是小A和小B:</p><p>小A，工作于传统软件行业(某社保局的软件外包公司)，每天工作内容就是和产品聊聊需求，改改业务逻辑。再不然就是和运营聊聊天，写几个SQL，生成下报表。又或者接到客服的通知，某某功能故障了，改改数据，然后下班部署上线。每天过的都是这种生活，技术零成长。<br>小B，工作于某国企，虽然能接触到一些中间件技术。然而，他只会订阅/发布消息。通俗点说，就是调调API。对为什么使用这些中间件啊？如何保证高可用啊？没有充分的认识。<br>庆幸的是两位朋友都很有上进心，于是博主写这篇文章，帮助他们复习一下关于消息队列中间件这块的要点</p><p>复习要点<br>本文大概围绕如下几点进行阐述:</p><p>为什么使用消息队列？<br>使用消息队列有什么缺点?<br>消息队列如何选型?<br>如何保证消息队列是高可用的？<br>如何保证消息不被重复消费?<br>如何保证消费的可靠性传输?<br>如何保证消息的顺序性？<br>我们围绕以上七点进行阐述。需要说明一下，本文不是《消息队列从入门到精通》这种课程，因此只是提供一个复习思路，而不是去教你们怎么调用消息队列的API。建议对消息队列不了解的人，去找点消息队列的博客看看，再看本文，收获更大</p><p>正文<br>1、为什么要使用消息队列?<br>分析:一个用消息队列的人，不知道为啥用，这就有点尴尬。没有复习这点，很容易被问蒙，然后就开始胡扯了。<br>回答:这个问题,咱只答三个最主要的应用场景(不可否认还有其他的，但是只答三个主要的),即以下六个字:解耦、异步、削峰</p><p>(1)解耦<br>传统模式:</p><p>传统模式的缺点：</p><p>系统间耦合性太强，如上图所示，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！<br>中间件模式:</p><p>中间件模式的的优点：</p><p>将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。<br>(2)异步<br>传统模式:</p><p>传统模式的缺点：</p><p>一些非必要的业务逻辑以同步的方式运行，太耗费时间。<br>中间件模式:</p><p>中间件模式的的优点：</p><p>将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度<br>(3)削峰<br>传统模式</p><p>传统模式的缺点：</p><p>并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常<br>中间件模式:</p><p>中间件模式的的优点：</p><p>系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。<br>2、使用了消息队列会有什么缺点?<br>分析:一个使用了MQ的项目，如果连这个问题都没有考虑过，就把MQ引进去了，那就给自己的项目带来了风险。我们引入一个技术，要对这个技术的弊端有充分的认识，才能做好预防。要记住，不要给公司挖坑！<br>回答:回答也很容易，从以下两个个角度来答</p><p>系统可用性降低:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性降低<br>系统复杂性增加:要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大。<br>但是，我们该用还是要用的。</p><p>3、消息队列如何选型?<br>先说一下，博主只会ActiveMQ,RabbitMQ,RocketMQ,Kafka，对什么ZeroMQ等其他MQ没啥理解，因此只能基于这四种MQ给出回答。<br>分析:既然在项目中用了MQ，肯定事先要对业界流行的MQ进行调研，如果连每种MQ的优缺点都没了解清楚，就拍脑袋依据喜好，用了某种MQ，还是给项目挖坑。如果面试官问:”你为什么用这种MQ？。”你直接回答”领导决定的。”这种回答就很LOW了。还是那句话，不要给公司挖坑。<br>回答:首先，咱先上ActiveMQ的社区，看看该MQ的更新频率:</p><p>Apache ActiveMQ 5.15.3 Release</p><p>Christopher L. Shannon posted on Feb 12, 2018</p><p>Apache ActiveMQ 5.15.2 Released</p><p>Christopher L. Shannon posted on Oct 23, 2017</p><p>Apache ActiveMQ 5.15.0 Released</p><p>Christopher L. Shannon posted on Jul 06, 2017</p><p>省略以下记录</p><p>…<br>我们可以看出，ActiveMq几个月才发一次版本，据说研究重心在他们的下一代产品Apollo。<br>接下来，我们再去RabbitMQ的社区去看一下,RabbitMQ的更新频率</p><p>RabbitMQ 3.7.3 release 30 January 2018</p><p>RabbitMQ 3.6.15 release 17 January 2018</p><p>RabbitMQ 3.7.2 release23 December 2017</p><p>RabbitMQ 3.7.1 release21 December 2017</p><p>省略以下记录</p><p>…<br>我们可以看出，RabbitMQ版本发布比ActiveMq频繁很多。至于RocketMQ和kafka就不带大家看了，总之也比ActiveMQ活跃的多。详情，可自行查阅。<br>再来一个性能对比表</p><p>特性    ActiveMQ    RabbitMQ    RocketMQ    kafka<br>开发语言    java    erlang    java    scala<br>单机吞吐量    万级    万级    10万级    10万级<br>时效性    ms级    us级    ms级    ms级以内<br>可用性    高(主从架构)    高(主从架构)    非常高(分布式架构)    非常高(分布式架构)<br>功能特性    成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好    基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富    MQ功能比较完备，扩展性佳    只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供，毕竟是为大数据准备的，在大数据领域应用广。<br>综合上面的材料得出以下两点:<br>(1)中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。<br>(2)大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。</p><p>4、如何保证消息队列是高可用的？<br>分析:在第二点说过了，引入消息队列后，系统的可用性下降。在生产中，没人使用单机模式的消息队列。因此，作为一个合格的程序员，应该对消息队列的高可用有很深刻的了解。如果面试的时候，面试官问，你们的消息中间件如何保证高可用的？你的回答只是表明自己只会订阅和发布消息，面试官就会怀疑你是不是只是自己搭着玩，压根没在生产用过。请做一个爱思考，会思考，懂思考的程序员。<br>回答:这问题，其实要对消息队列的集群模式要有深刻了解，才好回答。<br>以rcoketMQ为例，他的集群就有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。多master多slave模式部署架构图(网上找的,偷个懒，懒得画):<br>image<br>其实博主第一眼看到这个图，就觉得和kafka好像，只是NameServer集群，在kafka中是用zookeeper代替，都是用来保存和发现master和slave用的。通信过程如下:<br>Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。<br>那么kafka呢,为了对比说明直接上kafka的拓补架构图(也是找的，懒得画)<br>image<br>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。<br>至于rabbitMQ,也有普通集群和镜像集群模式，自行去了解，比较简单，两小时即懂。<br>要求，在回答高可用的问题时，应该能逻辑清晰的画出自己的MQ集群架构或清晰的叙述出来。</p><p>5、如何保证消息不被重复消费？<br>分析:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。<br>回答:先来说一下为什么会造成重复消费?<br>  其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。<br>  如何解决?这个问题针对业务场景来答分以下几点<br>  (1)比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。<br>  (2)再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。<br>  (3)如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。</p><p>6、如何保证消费的可靠性传输?<br>分析:我们在使用消息队列的过程中，应该做到消息不能多消费，也不能少消费。如果无法做到可靠性传输，可能给公司带来千万级别的财产损失。同样的，如果可靠性传输在使用过程中，没有考虑到，这不是给公司挖坑么，你可以拍拍屁股走了，公司损失的钱，谁承担。还是那句话，认真对待每一个项目，不要给公司挖坑。<br>回答:其实这个可靠性传输，每种MQ都要从三个角度来分析:生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据</p><p>RabbitMQ<br>(1)生产者丢数据<br>从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。<br>transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。<br>然而缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示（说好不上代码的，偷偷上了）:</p><p>channel.addConfirmListener(new ConfirmListener() {</p><p>@Override</p><p>public void handleNack(long deliveryTag, boolean multiple) throws IOException {</p><p>System.out.println(“nack: deliveryTag = “+deliveryTag+” multiple: “+multiple);</p><p>}</p><p>@Override</p><p>public void handleAck(long deliveryTag, boolean multiple) throws IOException {</p><p>System.out.println(“ack: deliveryTag = “+deliveryTag+” multiple: “+multiple);</p><p>}</p><p>});<br>(2)消息队列丢数据<br>处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。<br>那么如何持久化呢，这里顺便说一下吧，其实也很容易，就下面两步<br>1、将queue的持久化标识durable设置为true,则代表是一个持久的队列<br>2、发送消息的时候将deliveryMode=2<br>这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据<br>(3)消费者丢数据<br>消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。<br>至于解决方案，采用手动确认消息即可。</p><p>kafka<br>这里先引一张kafka Replication的数据流向图<br>image<br>Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader中pull数据。<br>针对上述情况，得出如下分析<br>(1)生产者丢数据<br>在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置</p><p>第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。<br>在producer端设置retries=MAX，一旦写入失败，这无限重试<br>(2)消息队列丢数据<br>针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。</p><p>replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本<br>min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系<br>这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据</p><p>(3)消费者丢数据<br>这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的<br>offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。<br>比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。<br>解决方案也很简单，改成手动提交即可。</p><p>ActiveMQ和RocketMQ<br>大家自行查阅吧</p><p>7、如何保证消息的顺序性？<br>分析:其实并非所有的公司都有这种业务需求，但是还是对这个问题要有所复习。<br>回答:针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。<br>有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？<br>这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。<br>总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 人工智能发展史 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能发展史</title>
      <link href="/2016/10/12/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E5%8F%B2/"/>
      <url>/2016/10/12/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E5%8F%B2/</url>
      
        <content type="html"><![CDATA[<p>我一直很好奇人工智能是如何提出来的，它背后有什么样的故事，在人工智能发展的这60年的时间中，又经历了什么？为什么现在才是人工智能的爆发点，未来人工智能又将走向何处？带着这样的问题我读了吴军博士的《智能时代》这本书，打开了我对人工智能的了解，这篇文章主要内容也来自于这本书。</p><p>我们这代人对人工智能的关注，来自于2016年AlphaGo大战世界著名围棋选手李世石，在比赛之前各方关注度非常高，国内各方媒体争相报道，预测这场比赛的结果，人们好奇人工智能现在智能到什么程度以及计算机如何和人下围棋，最终AlphaGo以4：1胜了李世明，大家都在感慨人工智能时代即将来临。仅仅过了一年，2017年5月27日AlphaGo的2.0版本3:0战胜围棋世界排名第一的柯洁九段，从此在AlphaGo面前已无人类对手。</p><p>计算机之所以能够战胜人类，是因为机器获得智能的方式和人类不同，它不是靠逻辑推理，而是靠大数据和算法。Google使用了几十万盘围棋高手之间的对弈的数据来训练AlphaGo，这是它获得所谓“智能”的原因。在计算方面，Google使用了几十万台服务器来训练AlphaGo下棋模型，并让不同的AlphaGo相互对弈上千万盘。第二个关键技术是启发式搜索算法-蒙特卡洛树搜索算法（英语：Monte Carlo tree search；简称：MCTS），它能将搜索的空间限制在非常有限的范围内，保证计算机能够快速找到好的下法。由此可见，下围棋这个看似智能型的问题，从本质上讲，是一个大数据和算法的问题。</p><p>说到人工智能，就不得不提计算机届的一个传奇人物：阿兰.图灵博士。1950年，图灵在《思想》（mind）杂志上发表了一篇《计算的机器和智能》的论文。在论文中，图灵既没有讲计算机怎样才能获得智能，也没有提出如何解决复杂问题的智能方法，知识提出了一个验证机器有无智能的的判别方法。</p><p>让一台机器和一个人坐在幕后，让一个裁判同时与幕后的人和机器进行交流，如果这个裁判无法判断自己交流的对象是人还是机器，就说明这台机器有了和人同等的智能。就是大名鼎鼎的图灵测试。后来，计算机科学家对此进行了补充，如果计算机实现了下面几件事情中的一件，就可以认为它有图灵所说的那种智能：</p><p>1、语音识别<br>2、机器翻译<br>3、文本的自动摘要或者写作<br>4、战胜人类的国际象棋冠军<br>5、自动回答问题<br>今天，计算机已经做到了上述的这几件事情，甚至还超额完成了任务，比如现在的围棋比国际象棋要高出6-8个数量级，当然，人类走到这一步并非一帆风顺，而是走了几十年的弯路。</p><p>人工智能的诞生：1943 - 1956<br>在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。</p><p>1956年的夏天，香农和一群年轻的学者在达特茅斯学院召开了一次头脑风暴式研讨会。会议的组织者是马文·闵斯基，约翰·麦卡锡和另两位资深科学家Claude Shannon以及Nathan Rochester，后者来自IBM。与会者包括Ray Solomonoff，Oliver Selfridge，Trenchard More，Arthur Samuel，Newell和Simon，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。</p><p>会议虽然叫做“达特茅斯夏季人工智能研究会议”，其实它不同于今天我们召开几天的学术会议，因为一来没有什么可以报告的科研成果，二来这个会议持续了一个暑假。事实上，这是一次头脑风暴式的讨论会，这10位年轻的学者讨论的是当时计算机尚未解决，甚至尚未开展研究的问题，包括人工智能、自然语言处理和神经网络等。</p><p>会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上人工智能的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为人工智能诞生的标志。</p><p>60年前的达特茅斯大学</p><p>黄金年代：1956 - 1974<br>达特茅斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。ARPA（国防高等研究计划署）等政府机构向这一新兴领域投入了大笔资金。</p><p>第一代AI研究者们非常乐观，曾作出了如下预言:</p><p>1958年，H. A. Simon，Allen Newell：“十年之内，数字计算机将成为国际象棋世界冠军。” “十年之内，数字计算机将发现并证明一个重要的数学定理。”<br>1965年，H. A. Simon：“二十年内，机器将能完成人能做到的一切工作。”<br>1967年，Marvin Minsky：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”<br>1970年，Marvin Minsky：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”<br>早期，人工智能使用传统的人工智能方法进行研究，什么是传统的人工智能研究呢？简单的讲，就是首先了解人类是如何产生智能的，然后让计算机按照人的思路去做。因此在语音识别、机器翻译等领域迟迟不能突破，人工智能研究陷入低谷。</p><p>第一次AI低谷：1974 - 1980<br>由于人工智能研究者们对项目难度评估不足，这除了导致承诺无法兑现外，还让人们当初的乐观期望遭到严重打击。到了70年代，人工智能开始遭遇批评，研究经费也被转移到那些目标明确的特定项目上。</p><p>1972年康奈尔大学的教授弗雷德.贾里尼克（Fred Jelinek)被要求到IBM做语音识别。在之前各个大学和研究这个问题已经花了20多年的时间，主流的研究方法有两个特点，一个是让计算机尽可能地模拟人的发音特点和听觉特征，一个是让计算机尽可能的方法理解人所讲的完整的语句。对于前一项研究，有被称为特征提取，后一项的研究大都使用传统人工智能的方法，它基于规则和语义。</p><p>贾里尼克任务，人的大脑是一个信息源，从思考到找到合适的语句，再通过发音说出来，是一个编码的过程，经过媒介传播到耳朵，是一个解码的过程。既然是一个典型的通讯问题，那就可以用解决通讯方法来解决问题，为此贾里尼克用两个数据模型（马尔科夫模型）分别描述信源和信道。然后使用大量的语音数据来训练。最后，贾里尼克团队花了4年团队，将语音识别从过去的70%提高到90%。后来人们尝试使用此方法来解决其他智能问题，但因为缺少数据，结果不太理想。</p><p>在当时，由于计算机性能的瓶颈、计算复杂性的指数级增长、数据量缺失等问题，一些难题看上去好像完全找不到答案。比如像今天已经比较常见的机器视觉功能在当时就不可能找到一个足够大的数据库来支撑程序去学习，机器无法吸收足够的数据量自然也就谈不上视觉方面的智能化。</p><p>项目的停滞不但让批评者有机可乘——1973年Lighthill针对英国人工智能研究状况的报告批评了人工智能在实现其“宏伟目标”上的完全失败，也影响到了项目资金的流向。人工智能遭遇了6年左右的低谷。</p><p>繁荣：1980 - 1987<br>在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。</p><p>受到日本刺激，其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。人工智能又迎来了大发展。</p><p>早期的专家系统Symbolics 3640</p><p>专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。</p><p>专家系统的能力来自于它们存储的专业知识。这是70年代以来AI研究的一个新方向。Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “70年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。”知识库系统和知识工程成为了80年代AI研究的主要方向。</p><p>1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。</p><p>第二次AI低谷：1987 - 1993<br>“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。</p><p>变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。</p><p>XCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题的牺牲品。专家系统的实用性仅仅局限于某些特定情景。到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。</p><p>1991年人们发现十年前日本人宏伟的“第五代工程”并没有实现。事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。与其他AI项目一样，期望比真正可能实现的要高得多。</p><p>走在正确的路上：1993 - 2005<br>现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。</p><p>“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。</p><p>第一次让全世界感到计算机智能水平有了质的飞跃实在1966年，IBM的超级计算机深蓝大战人类国际象棋冠军卡斯伯罗夫，卡斯伯罗夫是世界上最富传奇色彩的国际象棋世界冠军，这次比赛最后以4：2比分战胜了深蓝。对于这次比赛媒体认为深蓝虽然输了比赛，但这毕竟是国际象棋上计算机第一次战胜世界冠军两局。时隔一年后，改进后的深蓝卷土重来，以3.5：2.5的比分战胜了斯伯罗夫。自从1997年以后，计算机下棋的本领越来越高，进步超过人的想象。到了现在，棋类游戏中计算机已经可以完败任何人类。</p><p>深蓝实际上收集了世界上百位国际大师的对弈棋谱，供计算机学习。这样一来，深蓝其实看到了名家们在各种局面下的走法。当然深蓝也会考虑卡斯伯罗夫可能采用的走法，对不同的状态给出可能性评估，然后根据对方下一步走法对盘面的影响，核实这些可能性的估计，找到一个最有利自己的状态，并走出这步棋。因此深蓝团队其实把一个机器智能问题变成了一个大数据和大量计算的问题。</p><p>IBM“深蓝”战胜国际象棋世界冠军</p><p>越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。</p><p>Judea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。</p><p>大数据：2005 - 现在<br>从某种意义上讲，2005年是大数据元年，虽然大部分人感受不到数据带来的变化，但是一项科研成果却让全世界从事机器翻译的人感到震惊，那就是之前在机器翻译领域从来没有技术积累、不为人所知的Google，以巨大的优势打败了全世界所有机器翻译研究团队，一跃成为这个领域的领头羊。</p><p>就是Google花重金请到了当时世界上水平最高的机器翻译专家弗朗兹·奥科 (Franz Och)博士。奥科用了上万倍的数据来训练系统。量变的积累就导致了质变的发生。奥科能训练出一个六元模型，而当时大部分研究团队的数据量只够训练三元模型。简单地讲，一个 好的三元模型可以准确地构造英语句子中的短语和简单的句子成分之间的搭配，而六元模型则可以构造整个从句和复杂的句子成分之间的搭配，相当于将这些片段从一种语言到另一种语言直接对译过去了。不难想象，如果一个系统对大部分句子在很长的片段上直译，那么其准确性相比那些在词组单元做翻译的系统要准确得多。</p><p>如今在很多与“智能”有关的研究领域，比如图像识别和自然语言理解，如果所采用的方法无法利用数据量的优势，会被认为是落伍的。</p><p>数据驱动方法从20世纪70年代开始起步，在八九十年代得到缓慢但稳步的发展。进入21世纪后，由于互联网的出现，使得可用的数据量剧增，数据驱动方法的优势越来越明显，最终完成了从量变到质变的飞跃。如今很多需要类似人类智能才能做的事情，计算机已经可以胜任了，这得益于数据量的增加。</p><p>全世界各个领域数据不断向外扩展，渐渐形成了另外一个特点，那就是很多数据开始出现交叉，各个维度的数据从点和线渐渐连成了网，或者说，数据之间的关联性极大地增强，在这样的背景下，就出现了大数据。</p><p>大数据是一种思维方式的改变。现在的相比过去大了很多，量变带来了质变，思维方式、做事情的方法就应该和以往有所不同。这其实是帮助我们理解大数据概念的一把钥匙。在有大数据之前，计算机并不擅长解决需要人类智能来解决的问题，但是今天这些问题换个思路就可以解决了，其核心就是变智能问题为数据问题。由此，全世界开始了新的一轮技术革命——智能革命。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 人工智能发展史 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
